{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9071841",
   "metadata": {},
   "source": [
    "# StyleTTS2 Training on Google Colab\n",
    "## Train Cigdem TTS Model\n",
    "\n",
    "This notebook will help you train your Turkish TTS model on Google Colab with free GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754e1e5",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9756d",
   "metadata": {},
   "source": [
    "## Step 2: Clone StyleTTS2 Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/ElkhanAbbasov/TTS_Cigdem.git\n",
    "%cd TTS_Cigdem\n",
    "\n",
    "# Verify we're in the right place\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d32d32",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (INCLUDING einops-exts and click)\n",
    "!pip install -q SoundFile torchaudio munch pydub pyyaml librosa nltk matplotlib accelerate transformers einops einops-exts tqdm click\n",
    "!pip install -q git+https://github.com/resemble-ai/monotonic_align.git\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe353a",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive (for saving checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint backup folder in Drive\n",
    "!mkdir -p '/content/drive/MyDrive/Cigdem_TTS_Checkpoints'\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5f642",
   "metadata": {},
   "source": [
    "## Step 5: Verify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ebeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models from StyleTTS2\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "print(\"üì• Downloading pretrained StyleTTS2 models...\")\n",
    "print(\"This may take 5-10 minutes depending on connection speed.\\n\")\n",
    "\n",
    "# Create Models directory if it doesn't exist\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Download the pretrained model (LibriTTS base model)\n",
    "# This is the base model needed for fine-tuning\n",
    "print(\"Downloading base pretrained model...\")\n",
    "model_url = \"https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Models/LibriTTS/epochs_2nd_00020.pth\"\n",
    "model_path = \"Models/LibriTTS_pretrained.pth\"\n",
    "\n",
    "# Use wget instead of gdown for HuggingFace\n",
    "!wget -q --show-progress -O {model_path} {model_url}\n",
    "\n",
    "if os.path.exists(model_path) and os.path.getsize(model_path) > 100000:\n",
    "    print(f\"‚úÖ Base model downloaded: {model_path}\")\n",
    "    print(f\"   Size: {os.path.getsize(model_path) / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå Download failed! Trying alternative method...\")\n",
    "    # Try with curl as backup\n",
    "    !curl -L -o {model_path} {model_url}\n",
    "    \n",
    "if not os.path.exists(model_path):\n",
    "    print(\"\\n‚ö†Ô∏è Manual download needed:\")\n",
    "    print(f\"   1. Download from: {model_url}\")\n",
    "    print(f\"   2. Upload to: {model_path}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All pretrained models ready for fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865597a",
   "metadata": {},
   "source": [
    "## Step 5.5: Download Required Pretrained Models\n",
    "\n",
    "StyleTTS2 requires base pretrained models for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data exists\n",
    "import os\n",
    "\n",
    "train_list = \"Data/my_train_list.txt\"\n",
    "if os.path.exists(train_list):\n",
    "    with open(train_list, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"‚úÖ Training data found: {len(lines)} samples\")\n",
    "    print(\"\\nFirst 3 samples:\")\n",
    "    for line in lines[:3]:\n",
    "        print(f\"  {line.strip()}\")\n",
    "    \n",
    "    # Quick check that all audio files can be loaded\n",
    "    print(\"\\nüîç Checking all audio files...\")\n",
    "    import soundfile as sf\n",
    "    all_valid = True\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        path = line.strip().split('|')[0]\n",
    "        try:\n",
    "            wave, sr = sf.read(path)\n",
    "            print(f\"  ‚úì {i}: {path} ({sr} Hz)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó {i}: {path} - ERROR: {e}\")\n",
    "            all_valid = False\n",
    "    \n",
    "    if all_valid:\n",
    "        print(\"\\n‚úÖ All audio files can be loaded!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Some audio files have issues!\")\n",
    "else:\n",
    "    print(\"‚ùå Training data not found!\")\n",
    "    print(\"\\nüìÇ Current directory:\", os.getcwd())\n",
    "    print(\"\\nüìã Directory contents:\")\n",
    "    !ls -la\n",
    "    print(\"\\nüìã Looking for Data folder:\")\n",
    "    !ls -la Data/ 2>/dev/null || echo \"Data folder not found\"\n",
    "    print(\"\\n‚ö†Ô∏è Make sure the repository was cloned correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c088bdc",
   "metadata": {},
   "source": [
    "## Step 6: Configure Training Settings\n",
    "\n",
    "Update the config to use the pretrained model and prepare for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76173d1f",
   "metadata": {},
   "source": [
    "## Step 7: Start Training\n",
    "\n",
    "**IMPORTANT:** \n",
    "- Free Colab sessions last ~12 hours max\n",
    "- Training will run continuously\n",
    "- Checkpoints saved every 2 epochs to Models/Cigdem_TTS/\n",
    "- Backup to Google Drive regularly!\n",
    "- If disconnected, re-run from Step 6 to resume from last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84842fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training settings\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config_path = \"Configs/config_ft.yml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set the pretrained model path\n",
    "pretrained_model_path = \"Models/LibriTTS_pretrained.pth\"\n",
    "\n",
    "if os.path.exists(pretrained_model_path):\n",
    "    print(f\"‚úÖ Found pretrained model: {pretrained_model_path}\")\n",
    "    config['pretrained_model'] = pretrained_model_path\n",
    "    config['second_stage_load_pretrained'] = True\n",
    "    config['load_only_params'] = True  # Load only model weights, not optimizer state\n",
    "    print(\"   Will load pretrained weights for fine-tuning\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Pretrained model not found: {pretrained_model_path}\")\n",
    "    print(\"   Please run Step 5.5 to download the model\")\n",
    "    config['second_stage_load_pretrained'] = False\n",
    "    config['pretrained_model'] = \"\"\n",
    "\n",
    "# Ensure proper training settings\n",
    "config['batch_size'] = 2  # Small batch size for fine-tuning\n",
    "config['epochs'] = 100\n",
    "config['save_freq'] = 2\n",
    "\n",
    "# Save updated config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"\\nüìã Training Configuration:\")\n",
    "print(f\"  Pretrained model: {config.get('pretrained_model', 'None')}\")\n",
    "print(f\"  Load pretrained: {config.get('second_stage_load_pretrained', False)}\")\n",
    "print(f\"  Batch size: {config.get('batch_size', 'N/A')}\")\n",
    "print(f\"  Epochs: {config.get('epochs', 'N/A')}\")\n",
    "print(f\"  Save frequency: {config.get('save_freq', 'N/A')} epochs\")\n",
    "print(f\"  Log dir: {config.get('log_dir', 'N/A')}\")\n",
    "\n",
    "if config.get('second_stage_load_pretrained'):\n",
    "    print(\"\\n‚úÖ Ready to start training!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Cannot start training without pretrained model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training - runs continuously until complete or stopped\n",
    "# If this is a resume, it will automatically load the latest checkpoint\n",
    "!python train_finetune.py --config_path Configs/config_ft.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495a052",
   "metadata": {},
   "source": [
    "## Step 8: Backup Checkpoints to Google Drive (Run periodically)\n",
    "\n",
    "**Run this cell every 2-3 hours while training runs above!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy checkpoints to Google Drive\n",
    "!cp Models/Cigdem_TTS/epoch_*.pth '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/' 2>/dev/null || echo \"No checkpoints yet\"\n",
    "!cp Models/Cigdem_TTS/train.log '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/' 2>/dev/null || echo \"No log yet\"\n",
    "\n",
    "# List backed up files\n",
    "!ls -lh '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/'\n",
    "print(\"\\n‚úÖ Checkpoints backed up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a85eb9",
   "metadata": {},
   "source": [
    "## Step 9: View Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 20 lines of training log\n",
    "!tail -n 20 Models/Cigdem_TTS/train.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4846d",
   "metadata": {},
   "source": [
    "## Step 9: Download Results (After epoch 20+)\n",
    "\n",
    "Download checkpoints to test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip checkpoints for download\n",
    "!zip -r cigdem_tts_checkpoints.zip Models/Cigdem_TTS/epoch_*.pth Models/Cigdem_TTS/train.log\n",
    "\n",
    "from google.colab import files\n",
    "files.download('cigdem_tts_checkpoints.zip')\n",
    "\n",
    "print(\"‚úÖ Ready to download!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6eebde",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Important Notes:\n",
    "\n",
    "### Training Process:\n",
    "- Training runs **continuously** once started (Step 6)\n",
    "- Goes from epoch 1 ‚Üí 100 automatically\n",
    "- Each epoch takes ~2-3 minutes\n",
    "- **Don't re-run Step 6** unless training stops!\n",
    "\n",
    "### When to Test:\n",
    "- **Epoch 20+**: First test (may still be noisy)\n",
    "- **Epoch 30+**: Better quality expected\n",
    "- **Epoch 50+**: Good quality for your voice\n",
    "\n",
    "### If Colab Disconnects:\n",
    "1. Restore checkpoints from Google Drive:\n",
    "   ```python\n",
    "   !cp '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/epoch_*.pth' Models/Cigdem_TTS/\n",
    "   ```\n",
    "2. Re-run Step 6 (training cell)\n",
    "3. It will automatically resume from last checkpoint!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
