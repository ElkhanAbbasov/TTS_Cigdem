{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9071841",
   "metadata": {},
   "source": [
    "# StyleTTS2 Training on Google Colab\n",
    "## Train Cigdem TTS Model\n",
    "\n",
    "This notebook will help you train your Turkish TTS model on Google Colab with free GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754e1e5",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9756d",
   "metadata": {},
   "source": [
    "## Step 2: Clone StyleTTS2 Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/ElkhanAbbasov/TTS_Cigdem.git\n",
    "%cd TTS_Cigdem\n",
    "\n",
    "# Verify we're in the right place\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d32d32",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (INCLUDING einops-exts and click)\n",
    "!pip install -q SoundFile torchaudio munch pydub pyyaml librosa nltk matplotlib accelerate transformers einops einops-exts tqdm click\n",
    "!pip install -q git+https://github.com/resemble-ai/monotonic_align.git\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe353a",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive (for saving checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint backup folder in Drive\n",
    "!mkdir -p '/content/drive/MyDrive/Cigdem_TTS_Checkpoints'\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check disk space and clean up unnecessary files\n",
    "print(\"üíæ Disk Space Check:\")\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\nüßπ Cleaning up to free space...\")\n",
    "\n",
    "# Clean pip cache\n",
    "!pip cache purge\n",
    "\n",
    "# Clean apt cache\n",
    "!sudo apt-get clean\n",
    "\n",
    "# Remove unnecessary files\n",
    "!rm -rf /root/.cache/*\n",
    "!rm -rf /tmp/*\n",
    "\n",
    "print(\"\\nüíæ After cleanup:\")\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT: Colab has limited space (~70GB free)\")\n",
    "print(\"   Checkpoints are ~400MB each\")\n",
    "print(\"   With save_freq=2, you'll save ~50 checkpoints\")\n",
    "print(\"   Make sure to backup to Google Drive regularly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f0b1b",
   "metadata": {},
   "source": [
    "## Step 4.5: Free Up Disk Space (Critical!)\n",
    "\n",
    "Colab has limited disk space. We need to clean up to make room for training checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5f642",
   "metadata": {},
   "source": [
    "## Step 5: Verify Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ebeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models from StyleTTS2\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "print(\"üì• Downloading pretrained StyleTTS2 models...\")\n",
    "print(\"This may take 5-10 minutes depending on connection speed.\\n\")\n",
    "\n",
    "# Create Models directory if it doesn't exist\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Download the pretrained model (LibriTTS base model)\n",
    "# This is the base model needed for fine-tuning\n",
    "print(\"Downloading base pretrained model...\")\n",
    "model_url = \"https://huggingface.co/yl4579/StyleTTS2-LibriTTS/resolve/main/Models/LibriTTS/epochs_2nd_00020.pth\"\n",
    "model_path = \"Models/LibriTTS_pretrained.pth\"\n",
    "\n",
    "# Use wget instead of gdown for HuggingFace\n",
    "!wget -q --show-progress -O {model_path} {model_url}\n",
    "\n",
    "if os.path.exists(model_path) and os.path.getsize(model_path) > 100000:\n",
    "    print(f\"‚úÖ Base model downloaded: {model_path}\")\n",
    "    print(f\"   Size: {os.path.getsize(model_path) / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå Download failed! Trying alternative method...\")\n",
    "    # Try with curl as backup\n",
    "    !curl -L -o {model_path} {model_url}\n",
    "    \n",
    "if not os.path.exists(model_path):\n",
    "    print(\"\\n‚ö†Ô∏è Manual download needed:\")\n",
    "    print(f\"   1. Download from: {model_url}\")\n",
    "    print(f\"   2. Upload to: {model_path}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All pretrained models ready for fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865597a",
   "metadata": {},
   "source": [
    "## Step 5.5: Download Required Pretrained Models\n",
    "\n",
    "StyleTTS2 requires base pretrained models for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data exists\n",
    "import os\n",
    "\n",
    "train_list = \"Data/my_train_list.txt\"\n",
    "if os.path.exists(train_list):\n",
    "    with open(train_list, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"‚úÖ Training data found: {len(lines)} samples\")\n",
    "    print(\"\\nFirst 3 samples:\")\n",
    "    for line in lines[:3]:\n",
    "        print(f\"  {line.strip()}\")\n",
    "    \n",
    "    # Quick check that all audio files can be loaded\n",
    "    print(\"\\nüîç Checking all audio files...\")\n",
    "    import soundfile as sf\n",
    "    all_valid = True\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        path = line.strip().split('|')[0]\n",
    "        try:\n",
    "            wave, sr = sf.read(path)\n",
    "            print(f\"  ‚úì {i}: {path} ({sr} Hz)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó {i}: {path} - ERROR: {e}\")\n",
    "            all_valid = False\n",
    "    \n",
    "    if all_valid:\n",
    "        print(\"\\n‚úÖ All audio files can be loaded!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Some audio files have issues!\")\n",
    "else:\n",
    "    print(\"‚ùå Training data not found!\")\n",
    "    print(\"\\nüìÇ Current directory:\", os.getcwd())\n",
    "    print(\"\\nüìã Directory contents:\")\n",
    "    !ls -la\n",
    "    print(\"\\nüìã Looking for Data folder:\")\n",
    "    !ls -la Data/ 2>/dev/null || echo \"Data folder not found\"\n",
    "    print(\"\\n‚ö†Ô∏è Make sure the repository was cloned correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c088bdc",
   "metadata": {},
   "source": [
    "## Step 6: Configure Training Settings\n",
    "\n",
    "Update the config to use the pretrained model and prepare for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76173d1f",
   "metadata": {},
   "source": [
    "## Step 7: Start Training\n",
    "\n",
    "**IMPORTANT:** \n",
    "- Free Colab sessions last ~12 hours max\n",
    "- Training will run continuously\n",
    "- Checkpoints saved every 2 epochs to Models/Cigdem_TTS/\n",
    "- Backup to Google Drive regularly!\n",
    "- If disconnected, re-run from Step 6 to resume from last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84842fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training settings - AUTO-DETECT GPU TYPE\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "\n",
    "config_path = \"Configs/config_ft.yml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set the pretrained model path\n",
    "pretrained_model_path = \"Models/LibriTTS_pretrained.pth\"\n",
    "\n",
    "if os.path.exists(pretrained_model_path):\n",
    "    print(f\"‚úÖ Found pretrained model: {pretrained_model_path}\")\n",
    "    config['pretrained_model'] = pretrained_model_path\n",
    "    config['second_stage_load_pretrained'] = True\n",
    "    config['load_only_params'] = True  # Load only model weights, not optimizer state\n",
    "    print(\"   Will load pretrained weights for fine-tuning\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Pretrained model not found: {pretrained_model_path}\")\n",
    "    print(\"   Please run Step 5.5 to download the model\")\n",
    "    config['second_stage_load_pretrained'] = False\n",
    "    config['pretrained_model'] = \"\"\n",
    "\n",
    "# üîß AUTO-DETECT GPU AND OPTIMIZE SETTINGS\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n",
    "\n",
    "print(f\"\\nüéÆ GPU Detection:\")\n",
    "print(f\"   Type: {gpu_name}\")\n",
    "print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "\n",
    "# Optimize settings based on GPU\n",
    "if \"A100\" in gpu_name or gpu_memory > 70:\n",
    "    # A100 or V100 (80GB): Maximum performance\n",
    "    config['batch_size'] = 4\n",
    "    config['max_len'] = 300\n",
    "    print(\"\\n‚ö° A100/V100 Detected - Using HIGH PERFORMANCE settings:\")\n",
    "    print(\"   Batch size: 4 (4x faster training)\")\n",
    "    print(\"   Max length: 300 (longer sequences)\")\n",
    "elif \"T4\" in gpu_name or \"L4\" in gpu_name or (15 < gpu_memory < 30):\n",
    "    # T4 or L4 (16-24GB): Balanced settings\n",
    "    config['batch_size'] = 1\n",
    "    config['max_len'] = 200\n",
    "    print(\"\\n‚öôÔ∏è T4/L4 Detected - Using BALANCED settings:\")\n",
    "    print(\"   Batch size: 1 (stable training)\")\n",
    "    print(\"   Max length: 200 (memory-efficient)\")\n",
    "else:\n",
    "    # Unknown or smaller GPU: Conservative settings\n",
    "    config['batch_size'] = 1\n",
    "    config['max_len'] = 150\n",
    "    print(\"\\nüîß Using CONSERVATIVE settings for safety:\")\n",
    "    print(\"   Batch size: 1\")\n",
    "    print(\"   Max length: 150\")\n",
    "\n",
    "config['epochs'] = 100\n",
    "config['save_freq'] = 5  # Save less frequently to save disk space\n",
    "\n",
    "# Save updated config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"  Pretrained model: {config.get('pretrained_model', 'None')}\")\n",
    "print(f\"  Load pretrained: {config.get('second_stage_load_pretrained', False)}\")\n",
    "print(f\"  Batch size: {config.get('batch_size', 'N/A')}\")\n",
    "print(f\"  Max length: {config.get('max_len', 'N/A')}\")\n",
    "print(f\"  Epochs: {config.get('epochs', 'N/A')}\")\n",
    "print(f\"  Save frequency: {config.get('save_freq', 'N/A')} epochs\")\n",
    "print(f\"  Log dir: {config.get('log_dir', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training - runs continuously until complete or stopped\n",
    "# If this is a resume, it will automatically load the latest checkpoint\n",
    "!python train_finetune.py --config_path Configs/config_ft.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495a052",
   "metadata": {},
   "source": [
    "## Step 8: Backup Checkpoints to Google Drive (Run periodically)\n",
    "\n",
    "**Run this cell every 2-3 hours while training runs above!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup ONLY the latest checkpoint to Google Drive (saves space!)\n",
    "import os\n",
    "\n",
    "# Create backup directory if it doesn't exist\n",
    "!mkdir -p '/content/drive/MyDrive/Cigdem_TTS_Checkpoints'\n",
    "\n",
    "# Check what checkpoints exist\n",
    "checkpoint_dir = \"Models/Cigdem_TTS\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = !ls {checkpoint_dir}/epoch_*.pth 2>/dev/null || echo \"\"\n",
    "    checkpoints = [c for c in checkpoints if c and 'epoch_' in c]\n",
    "    \n",
    "    if checkpoints:\n",
    "        # Get only the LATEST checkpoint (highest epoch number)\n",
    "        latest_checkpoint = sorted(checkpoints)[-1]\n",
    "        \n",
    "        print(f\"üì¶ Found {len(checkpoints)} checkpoints\")\n",
    "        print(f\"‚úÖ Backing up LATEST: {os.path.basename(latest_checkpoint)}\")\n",
    "        \n",
    "        # Copy latest checkpoint to Google Drive\n",
    "        !cp '{latest_checkpoint}' '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/latest_checkpoint.pth'\n",
    "        \n",
    "        # Also save with epoch number for tracking\n",
    "        !cp '{latest_checkpoint}' '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/'\n",
    "        \n",
    "        # Copy training log\n",
    "        !cp Models/Cigdem_TTS/train.log '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/' 2>/dev/null || echo \"No log yet\"\n",
    "        \n",
    "        print(\"\\nüìÇ Google Drive contents:\")\n",
    "        !ls -lh '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/'\n",
    "        \n",
    "        print(f\"\\n‚úÖ Latest checkpoint backed up!\")\n",
    "        print(f\"   File: {os.path.basename(latest_checkpoint)}\")\n",
    "        print(f\"   Also saved as: latest_checkpoint.pth (easy to find!)\")\n",
    "        \n",
    "        # Clean up old local checkpoints to save Colab disk space\n",
    "        if len(checkpoints) > 2:\n",
    "            old_checkpoints = sorted(checkpoints)[:-2]  # Keep last 2 locally\n",
    "            print(f\"\\nüßπ Cleaning up {len(old_checkpoints)} old local checkpoints...\")\n",
    "            for ckpt in old_checkpoints:\n",
    "                !rm '{ckpt}'\n",
    "                print(f\"   Deleted: {os.path.basename(ckpt)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No checkpoints found yet\")\n",
    "        print(\"   Training hasn't saved any checkpoints yet\")\n",
    "else:\n",
    "    print(\"‚ùå Checkpoint directory not found\")\n",
    "    print(f\"   Looking for: {checkpoint_dir}\")\n",
    "    !pwd\n",
    "    !ls -la Models/ 2>/dev/null || echo \"Models folder not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a85eb9",
   "metadata": {},
   "source": [
    "## Step 9: View Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 20 lines of training log\n",
    "!tail -n 20 Models/Cigdem_TTS/train.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4846d",
   "metadata": {},
   "source": [
    "## Step 9: Download Results (After epoch 20+)\n",
    "\n",
    "Download checkpoints to test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoints from Google Drive (best results)\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# First, check what's in Google Drive\n",
    "print(\"üìÇ Checkpoints in Google Drive:\")\n",
    "!ls -lh '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/'\n",
    "\n",
    "# Find the best checkpoint (highest epoch number)\n",
    "drive_checkpoints = !ls '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/epoch_*.pth' 2>/dev/null || echo \"\"\n",
    "drive_checkpoints = [c for c in drive_checkpoints if c and 'epoch_' in c]\n",
    "\n",
    "if drive_checkpoints:\n",
    "    # Sort to get the latest checkpoint\n",
    "    latest_checkpoint = sorted(drive_checkpoints)[-1]\n",
    "    print(f\"\\nüì• Downloading latest checkpoint: {os.path.basename(latest_checkpoint)}\")\n",
    "    \n",
    "    # Copy to local for download\n",
    "    !cp '{latest_checkpoint}' ./best_checkpoint.pth\n",
    "    !cp '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/train.log' ./train.log 2>/dev/null || echo \"No log\"\n",
    "    \n",
    "    # Download\n",
    "    if os.path.exists('best_checkpoint.pth'):\n",
    "        files.download('best_checkpoint.pth')\n",
    "        print(\"‚úÖ Downloaded!\")\n",
    "    \n",
    "    if os.path.exists('train.log'):\n",
    "        files.download('train.log')\n",
    "        print(\"‚úÖ Training log downloaded!\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoints found in Google Drive!\")\n",
    "    print(\"   Make sure you ran Step 8 to backup checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6eebde",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Important Notes:\n",
    "\n",
    "### Training Process:\n",
    "- Training runs **continuously** once started (Step 6)\n",
    "- Goes from epoch 1 ‚Üí 100 automatically\n",
    "- Each epoch takes ~2-3 minutes\n",
    "- **Don't re-run Step 6** unless training stops!\n",
    "\n",
    "### When to Test:\n",
    "- **Epoch 20+**: First test (may still be noisy)\n",
    "- **Epoch 30+**: Better quality expected\n",
    "- **Epoch 50+**: Good quality for your voice\n",
    "\n",
    "### If Colab Disconnects:\n",
    "1. Restore checkpoints from Google Drive:\n",
    "   ```python\n",
    "   !cp '/content/drive/MyDrive/Cigdem_TTS_Checkpoints/epoch_*.pth' Models/Cigdem_TTS/\n",
    "   ```\n",
    "2. Re-run Step 6 (training cell)\n",
    "3. It will automatically resume from last checkpoint!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
